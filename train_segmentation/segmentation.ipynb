{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de41a88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pdimport os\n",
    "import json\n",
    "from PIL import Image, ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "    \n",
    "class NestedUNet(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            \n",
    "            return nn.Sigmoid()(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e966fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#given the confirmed folder path, return list of Image and corresponding label file path as a list\n",
    "def make_pth_list(confirmed_pth):\n",
    "    images_pth_list = []\n",
    "    labels_pth_list = []\n",
    "    confirmed_list = os.listdir(confirmed_pth)\n",
    "    for num in confirmed_list:\n",
    "        num_pth = os.path.join(confirmed_pth,num)\n",
    "\n",
    "        num_images_pth = os.path.join(num_pth,\"images/cur\")\n",
    "        num_images_list = os.listdir(num_images_pth)\n",
    "\n",
    "        num_labels_pth = os.path.join(num_pth,\"labels\")\n",
    "        num_labels_list = os.listdir(num_labels_pth)\n",
    "        \n",
    "        for i in range(len(num_labels_list)):\n",
    "            num_pth = os.path.join(confirmed_pth,num)\n",
    "            image_pth= os.path.join(num_images_pth,num_images_list[i])\n",
    "            images_pth_list.append(image_pth)\n",
    "\n",
    "            label_pth = os.path.join(num_labels_pth,num_labels_list[i])\n",
    "            labels_pth_list.append(label_pth)\n",
    "    return images_pth_list, labels_pth_list      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e451e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskGenerator():\n",
    "    \"\"\"Segmentation Mask Generator.\n",
    "\n",
    "    Notes:\n",
    "        Pretrained Nested UNet generate segmentation mask from smoke-including images.\n",
    "        Segmentation operate with image of size 128x128, with padding zeros to soure images to prevent boundary execption.\n",
    "        Get a center position from given bbox label data.\n",
    "        \n",
    "        Parameters:\n",
    "            pretrained (tensor): Given pretrained Nested UNet for direct segmentation\n",
    "            image (str): Path of source image (.jpg)\n",
    "            bbox (str): Path of bbox label data (.json)\n",
    "            threshold (float): Segmentation output thresholding factor for binary mask synthetic\n",
    "        \n",
    "        Returns:\n",
    "            mask (float): Segmented binary mask that has smoke\n",
    "            masked_image (float): image conclude that only smoke from given source image\n",
    "            image (float): Given source image\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pretrained, image, bbox, threshold = 0.5, target_size = 128., device = 'cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.crop = int(target_size / 2)\n",
    "        self.segmentation = NestedUNet(1,3)\n",
    "        self.segmentation.load_state_dict(torch.load(pretrained))\n",
    "        if device == 'cuda':\n",
    "            self.segmentation = self.segmentation.to(device)\n",
    "        self.image_path = image\n",
    "        self.bbox_path = bbox\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        print(self.image_path)\n",
    "        image = np.asarray(Image.open(self.image_path))/255.\n",
    "        with open(self.bbox_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        p_1 = data[\"objects\"][0][0][\"points\"][0]\n",
    "        p_2 = data[\"objects\"][0][0][\"points\"][1]\n",
    "        W1 = round((p_1[\"y\"]+p_2[\"y\"])/2) # Get a center position of given bounding box label\n",
    "        H1 = round((p_1[\"x\"]+p_2[\"x\"])/2)\n",
    "        w, h, c = image.shape\n",
    "        \n",
    "        image = torch.tensor(image, dtype = torch.float32).permute(2,0,1).unsqueeze(0)\n",
    "        pad = nn.ZeroPad2d(self.crop) # zero pad for a case that bbox center is at boundary\n",
    "        mask = pad(torch.zeros((1, 1, w, h)))\n",
    "        image_pad = pad(image)\n",
    "        \n",
    "        bbox_center = [W1, H1]\n",
    "        image_cropped = image_pad[:, :,\n",
    "                                  bbox_center[0]:bbox_center[0]+self.crop * 2,   # 128 x 128 crop, considering padded boundary\n",
    "                                  bbox_center[1]:bbox_center[1]+self.crop * 2]\n",
    "        segmented = self.segmentation.forward(image_cropped)\n",
    "        mask[0, 0,\n",
    "             bbox_center[0]:bbox_center[0]+self.crop * 2,   # 128 x 128 crop, considering padded boundary\n",
    "             bbox_center[1]:bbox_center[1]+self.crop * 2] = segmented\n",
    "        \n",
    "        mask = mask[0, 0, :, :] # 2d mask size of (W+pad, H+pad), it prevents boundary exception\n",
    "        mask_stack = torch.stack((mask, mask, mask), dim = 0) # 3 channel stacking for masking\n",
    "        masked_image = mask_stack * image_pad.squeeze(0) # no batch\n",
    "        \n",
    "        mask = mask[self.crop:self.crop + w, self.crop:self.crop + h] # crop (W, H)\n",
    "        masked_image = masked_image[:, self.crop:self.crop + w, self.crop:self.crop + h] # crop (3, W, H)\n",
    "        mask = mask.cpu().detach().numpy()\n",
    "        mask[mask<self.threshold] = 0\n",
    "        mask[mask>self.threshold] = 1 #\n",
    "        masked_image = masked_image.permute(1,2,0).cpu().detach().numpy() # convert to PIL format\n",
    "        return mask, masked_image, image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f32451",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def save_mask(confirmed_pth, model_pth):\n",
    "    confirmed_list = os.listdir(confirmed_pth)\n",
    "        num_pth = os.path.join(confirmed_pth,num)\n",
    "        \n",
    "        ##make mask directory\n",
    "        num_masks_pth = os.path.join(num_pth,'masks')\n",
    "        if os.path.exists(num_masks_pth)==False:\n",
    "            os.mkdir(num_masks_pth)\n",
    "        \n",
    "        #make image list\n",
    "        num_images_pth = os.path.join(num_pth,\"images/cur\")\n",
    "        num_images_list = os.listdir(num_images_pth)\n",
    "        \n",
    "        #make label list\n",
    "        num_labels_pth = os.path.join(num_pth,\"labels\")\n",
    "        num_labels_list = os.listdir(num_labels_pth)\n",
    "        \n",
    "        \n",
    "        for i in range(len(num_labels_list)):\n",
    "            image_file_name = num_images_list[i] \n",
    "            mask_pth = os.path.join(num_masks_pth,image_file_name)\n",
    "            \n",
    "            image_pth= os.path.join(num_images_pth,num_images_list[i])\n",
    "\n",
    "            label_pth = os.path.join(num_labels_pth,num_labels_list[i])\n",
    "            x = MaskGenerator(model_pth,image_pth,label_pth)\n",
    "            mask,masked_image,image = x.forward(0)\n",
    "            mask_array = [mask,mask,mask]\n",
    "            final_mask = np.stack(mask_array, axis=2)\n",
    "            plt.imsave(mask_pth,final_mask)\n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f4312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pth = \"./pretrained.pth\"\n",
    "confirmed_pth = \"./datasets/confirmed\"\n",
    "images_pth_list, labels_pth_list = make_pth_list(confirmed_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8e400",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_mask(confirmed_pth, model_pth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
